{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0657067-e86c-449f-9db3-60de81d837d8",
   "metadata": {},
   "source": [
    "# Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3fc7ab1-1873-445d-ba23-5500740b9637",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16528\\95499780.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# import module\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# for loss function\n",
    "from typing import Optional\n",
    "#from kornia.utils.one_hot import one_hot\n",
    "\n",
    "from models import DP_UNet, DP_resUNet\n",
    "from patch_function import makepatches_overlay, \\\n",
    "makepatches_overlay_normap, \\\n",
    "patchesback_overlay, \\\n",
    "find_ksp_andpadding, \\\n",
    "pad_back, \\\n",
    "pad_for_256, \\\n",
    "pad_back_256\n",
    "from data_preprocess_and_loader import Dataset, Dataset_val\n",
    "from losses_unet3d import DiceLoss, GeneralizedDiceLoss, compute_per_channel_dice\n",
    "from train_and_val import train, validation\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19bd75d-cea0-4acf-a69d-51f41da26439",
   "metadata": {},
   "source": [
    "# Define Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9945ade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TWCC\n",
    "train_image_path = '/work/nymu834wklee/TVGH/brain_tumor_nomask_biparametric_twcc4/imagesTr'\n",
    "val_image_path = '/work/nymu834wklee/TVGH/brain_tumor_nomask_biparametric_twcc4/imagesVal'\n",
    "\n",
    "k = os.listdir(train_image_path)\n",
    "list_tra = []\n",
    "for j in k:\n",
    "    list_tra.append(train_image_path + '/' + j)\n",
    "list_val = []\n",
    "k = os.listdir(val_image_path)\n",
    "for j in k:\n",
    "    list_val.append(val_image_path + '/' + j)\n",
    "\n",
    "train_image_path = '/work/nymu834wklee/TCVGH/brain_tumor_nomask_biparametric_twcc4/imagesTr'\n",
    "val_image_path = '/work/nymu834wklee/TCVGH/brain_tumor_nomask_biparametric_twcc4/imagesVal'\n",
    "\n",
    "k = os.listdir(train_image_path)\n",
    "for j in k:\n",
    "    list_tra.append(train_image_path + '/' + j)\n",
    "k = os.listdir(val_image_path)\n",
    "for j in k:\n",
    "    list_val.append(val_image_path + '/' + j)\n",
    "\n",
    "train_image_path = '/work/nymu834wklee/BraTS/raw_without_nonenhance_twcc4/imagesTr' #path that save the training data\n",
    "val_image_path = '/work/nymu834wklee/BraTS/raw_without_nonenhance_twcc4/imagesVal'\n",
    "\n",
    "k = os.listdir(train_image_path)\n",
    "for j in k:\n",
    "    list_tra.append(train_image_path + '/' + j)\n",
    "k = os.listdir(val_image_path)\n",
    "for j in k:\n",
    "    list_val.append(val_image_path + '/' + j)\n",
    "\n",
    "train_image_path = '/work/nymu834wklee/UCSF/raw_without_nonenhance_twcc4/imagesTr' #path that save the training data\n",
    "val_image_path = '/work/nymu834wklee/UCSF/raw_without_nonenhance_twcc4/imagesVal'\n",
    "\n",
    "k = os.listdir(train_image_path)\n",
    "for j in k:\n",
    "    list_tra.append(train_image_path + '/' + j)\n",
    "k = os.listdir(val_image_path)\n",
    "for j in k:\n",
    "    list_val.append(val_image_path + '/' + j)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ec2fc24-7254-4b7a-91d4-34ab3bfc1f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設置dataloader\n",
    "#biparametric = True\n",
    "train_data = Dataset(list_tra, biparametric=True)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    num_workers=8,\n",
    "    shuffle = True)\n",
    "\n",
    "val_data = Dataset_val(list_val, biparametric=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_data,           \n",
    "    batch_size=2,          \n",
    "    num_workers=8,\n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0413245d-6a7e-4c13-b963-e095aba150dc",
   "metadata": {},
   "source": [
    "# Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec6a8bac-c7f5-4740-9821-296a5e100707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialization\n",
    "\n",
    "model = DP_resUNet(img_channels = 2, n_classes = 1).cuda()\n",
    "model= nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "#model = DP_UNet(img_channels = 2, n_classes = 2).cuda()\n",
    "\n",
    "# define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, gamma=0.95)\n",
    "\n",
    "# loss function\n",
    "criterion_DICE = DiceLoss()\n",
    "criterion_GDL = GeneralizedDiceLoss()\n",
    "\n",
    "loss_fun = (criterion_DICE,criterion_GDL,compute_per_channel_dice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4c80e7-e848-47b9-aab5-bf9a708c20e1",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a5715ea-8d86-4cf1-94d7-06e196b0a9d4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start.\n",
      "| epoch   1 |   100/ 3779 batches |  ms/batch 53025.93 |  loss_dice  0.98  |  loss_gdl  0.98  |  dice_score  0.02  | \n",
      "| epoch   1 |   200/ 3779 batches |  ms/batch 43018.03 |  loss_dice  0.97  |  loss_gdl  0.97  |  dice_score  0.03  | \n",
      "| epoch   1 |   300/ 3779 batches |  ms/batch 41040.20 |  loss_dice  0.96  |  loss_gdl  0.96  |  dice_score  0.04  | \n",
      "| epoch   1 |   400/ 3779 batches |  ms/batch 47394.27 |  loss_dice  0.96  |  loss_gdl  0.96  |  dice_score  0.04  | \n",
      "| epoch   1 |   500/ 3779 batches |  ms/batch 45027.48 |  loss_dice  0.95  |  loss_gdl  0.95  |  dice_score  0.05  | \n",
      "| epoch   1 |   600/ 3779 batches |  ms/batch 39054.74 |  loss_dice  0.95  |  loss_gdl  0.95  |  dice_score  0.05  | \n",
      "| epoch   1 |   700/ 3779 batches |  ms/batch 46712.45 |  loss_dice  0.94  |  loss_gdl  0.94  |  dice_score  0.06  | \n",
      "| epoch   1 |   800/ 3779 batches |  ms/batch 43758.56 |  loss_dice  0.94  |  loss_gdl  0.94  |  dice_score  0.06  | \n",
      "| epoch   1 |   900/ 3779 batches |  ms/batch 40156.99 |  loss_dice  0.93  |  loss_gdl  0.93  |  dice_score  0.07  | \n",
      "| epoch   1 |  1000/ 3779 batches |  ms/batch 47673.55 |  loss_dice  0.93  |  loss_gdl  0.93  |  dice_score  0.07  | \n",
      "| epoch   1 |  1100/ 3779 batches |  ms/batch 41249.39 |  loss_dice  0.92  |  loss_gdl  0.92  |  dice_score  0.08  | \n",
      "| epoch   1 |  1200/ 3779 batches |  ms/batch 47669.47 |  loss_dice  0.91  |  loss_gdl  0.91  |  dice_score  0.09  | \n",
      "| epoch   1 |  1300/ 3779 batches |  ms/batch 42914.58 |  loss_dice  0.90  |  loss_gdl  0.90  |  dice_score  0.10  | \n",
      "| epoch   1 |  1400/ 3779 batches |  ms/batch 46039.69 |  loss_dice  0.90  |  loss_gdl  0.90  |  dice_score  0.10  | \n",
      "| epoch   1 |  1500/ 3779 batches |  ms/batch 46228.90 |  loss_dice  0.89  |  loss_gdl  0.89  |  dice_score  0.11  | \n",
      "| epoch   1 |  1600/ 3779 batches |  ms/batch 44871.95 |  loss_dice  0.88  |  loss_gdl  0.88  |  dice_score  0.12  | \n",
      "| epoch   1 |  1700/ 3779 batches |  ms/batch 45091.73 |  loss_dice  0.88  |  loss_gdl  0.88  |  dice_score  0.12  | \n",
      "| epoch   1 |  1800/ 3779 batches |  ms/batch 45279.50 |  loss_dice  0.87  |  loss_gdl  0.87  |  dice_score  0.13  | \n",
      "| epoch   1 |  1900/ 3779 batches |  ms/batch 45470.31 |  loss_dice  0.86  |  loss_gdl  0.86  |  dice_score  0.14  | \n",
      "| epoch   1 |  2000/ 3779 batches |  ms/batch 49379.25 |  loss_dice  0.85  |  loss_gdl  0.85  |  dice_score  0.15  | \n",
      "| epoch   1 |  2100/ 3779 batches |  ms/batch 47108.89 |  loss_dice  0.84  |  loss_gdl  0.84  |  dice_score  0.16  | \n",
      "| epoch   1 |  2200/ 3779 batches |  ms/batch 44184.76 |  loss_dice  0.83  |  loss_gdl  0.83  |  dice_score  0.17  | \n",
      "| epoch   1 |  2300/ 3779 batches |  ms/batch 47852.17 |  loss_dice  0.82  |  loss_gdl  0.82  |  dice_score  0.18  | \n",
      "| epoch   1 |  2400/ 3779 batches |  ms/batch 47785.78 |  loss_dice  0.82  |  loss_gdl  0.82  |  dice_score  0.18  | \n",
      "| epoch   1 |  2500/ 3779 batches |  ms/batch 44883.78 |  loss_dice  0.81  |  loss_gdl  0.81  |  dice_score  0.19  | \n",
      "| epoch   1 |  2600/ 3779 batches |  ms/batch 46429.73 |  loss_dice  0.80  |  loss_gdl  0.80  |  dice_score  0.20  | \n",
      "| epoch   1 |  2700/ 3779 batches |  ms/batch 50056.30 |  loss_dice  0.79  |  loss_gdl  0.79  |  dice_score  0.21  | \n",
      "| epoch   1 |  2800/ 3779 batches |  ms/batch 48988.17 |  loss_dice  0.78  |  loss_gdl  0.78  |  dice_score  0.22  | \n",
      "| epoch   1 |  2900/ 3779 batches |  ms/batch 41222.21 |  loss_dice  0.77  |  loss_gdl  0.77  |  dice_score  0.23  | \n",
      "| epoch   1 |  3000/ 3779 batches |  ms/batch 48932.42 |  loss_dice  0.77  |  loss_gdl  0.77  |  dice_score  0.23  | \n",
      "| epoch   1 |  3100/ 3779 batches |  ms/batch 46016.60 |  loss_dice  0.76  |  loss_gdl  0.76  |  dice_score  0.24  | \n",
      "| epoch   1 |  3200/ 3779 batches |  ms/batch 44756.51 |  loss_dice  0.76  |  loss_gdl  0.76  |  dice_score  0.24  | \n",
      "| epoch   1 |  3300/ 3779 batches |  ms/batch 45457.49 |  loss_dice  0.75  |  loss_gdl  0.75  |  dice_score  0.25  | \n",
      "| epoch   1 |  3400/ 3779 batches |  ms/batch 49803.92 |  loss_dice  0.75  |  loss_gdl  0.75  |  dice_score  0.25  | \n",
      "| epoch   1 |  3500/ 3779 batches |  ms/batch 46419.99 |  loss_dice  0.74  |  loss_gdl  0.74  |  dice_score  0.26  | \n",
      "| epoch   1 |  3600/ 3779 batches |  ms/batch 42710.93 |  loss_dice  0.74  |  loss_gdl  0.74  |  dice_score  0.26  | \n",
      "| epoch   1 |  3700/ 3779 batches |  ms/batch 49896.37 |  loss_dice  0.73  |  loss_gdl  0.73  |  dice_score  0.27  | \n",
      "| epoch   1 |  3779/ 3779 batches |  ms/batch 34686.40 |  loss_dice  0.73  |  loss_gdl  0.73  |  dice_score  0.27  | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   1 |   100/  436 batches |  ms/batch 21273.57 |  loss_dice  0.48  |  loss_gdl  0.48  |  dice_score  0.52  | \n",
      "| epoch   1 |   200/  436 batches |  ms/batch 24027.70 |  loss_dice  0.53  |  loss_gdl  0.53  |  dice_score  0.47  | \n",
      "| epoch   1 |   300/  436 batches |  ms/batch 53138.71 |  loss_dice  0.60  |  loss_gdl  0.60  |  dice_score  0.40  | \n",
      "| epoch   1 |   400/  436 batches |  ms/batch 26217.70 |  loss_dice  0.56  |  loss_gdl  0.56  |  dice_score  0.44  | \n",
      "| epoch   1 |   436/  436 batches |  ms/batch 11600.08 |  loss_dice  0.55  |  loss_gdl  0.55  |  dice_score  0.45  | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 1865.43s\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   100/ 3779 batches |  ms/batch 54323.82 |  loss_dice  0.58  |  loss_gdl  0.58  |  dice_score  0.42  | \n",
      "| epoch   2 |   200/ 3779 batches |  ms/batch 41694.61 |  loss_dice  0.56  |  loss_gdl  0.56  |  dice_score  0.44  | \n",
      "| epoch   2 |   300/ 3779 batches |  ms/batch 43038.26 |  loss_dice  0.55  |  loss_gdl  0.55  |  dice_score  0.45  | \n",
      "| epoch   2 |   400/ 3779 batches |  ms/batch 41473.93 |  loss_dice  0.56  |  loss_gdl  0.56  |  dice_score  0.44  | \n",
      "| epoch   2 |   500/ 3779 batches |  ms/batch 40630.41 |  loss_dice  0.56  |  loss_gdl  0.56  |  dice_score  0.44  | \n",
      "| epoch   2 |   600/ 3779 batches |  ms/batch 45267.87 |  loss_dice  0.56  |  loss_gdl  0.56  |  dice_score  0.44  | \n",
      "| epoch   2 |   700/ 3779 batches |  ms/batch 43734.11 |  loss_dice  0.55  |  loss_gdl  0.55  |  dice_score  0.45  | \n",
      "| epoch   2 |   800/ 3779 batches |  ms/batch 43968.28 |  loss_dice  0.55  |  loss_gdl  0.55  |  dice_score  0.45  | \n",
      "| epoch   2 |   900/ 3779 batches |  ms/batch 43621.77 |  loss_dice  0.55  |  loss_gdl  0.55  |  dice_score  0.45  | \n",
      "| epoch   2 |  1000/ 3779 batches |  ms/batch 41765.76 |  loss_dice  0.55  |  loss_gdl  0.55  |  dice_score  0.45  | \n",
      "| epoch   2 |  1100/ 3779 batches |  ms/batch 41576.42 |  loss_dice  0.55  |  loss_gdl  0.55  |  dice_score  0.45  | \n",
      "| epoch   2 |  1200/ 3779 batches |  ms/batch 50154.06 |  loss_dice  0.55  |  loss_gdl  0.55  |  dice_score  0.45  | \n",
      "| epoch   2 |  1300/ 3779 batches |  ms/batch 46700.01 |  loss_dice  0.55  |  loss_gdl  0.55  |  dice_score  0.45  | \n",
      "| epoch   2 |  1400/ 3779 batches |  ms/batch 43699.98 |  loss_dice  0.55  |  loss_gdl  0.55  |  dice_score  0.45  | \n",
      "| epoch   2 |  1500/ 3779 batches |  ms/batch 43041.57 |  loss_dice  0.55  |  loss_gdl  0.55  |  dice_score  0.45  | \n",
      "| epoch   2 |  1600/ 3779 batches |  ms/batch 43928.30 |  loss_dice  0.54  |  loss_gdl  0.54  |  dice_score  0.46  | \n",
      "| epoch   2 |  1700/ 3779 batches |  ms/batch 48800.90 |  loss_dice  0.54  |  loss_gdl  0.54  |  dice_score  0.46  | \n",
      "| epoch   2 |  1800/ 3779 batches |  ms/batch 49092.83 |  loss_dice  0.54  |  loss_gdl  0.54  |  dice_score  0.46  | \n",
      "| epoch   2 |  1900/ 3779 batches |  ms/batch 46984.45 |  loss_dice  0.54  |  loss_gdl  0.54  |  dice_score  0.46  | \n",
      "| epoch   2 |  2000/ 3779 batches |  ms/batch 50631.22 |  loss_dice  0.54  |  loss_gdl  0.54  |  dice_score  0.46  | \n",
      "| epoch   2 |  2100/ 3779 batches |  ms/batch 46862.98 |  loss_dice  0.54  |  loss_gdl  0.54  |  dice_score  0.46  | \n",
      "| epoch   2 |  2200/ 3779 batches |  ms/batch 46866.62 |  loss_dice  0.54  |  loss_gdl  0.54  |  dice_score  0.46  | \n",
      "| epoch   2 |  2300/ 3779 batches |  ms/batch 47668.03 |  loss_dice  0.54  |  loss_gdl  0.54  |  dice_score  0.46  | \n",
      "| epoch   2 |  2400/ 3779 batches |  ms/batch 47348.66 |  loss_dice  0.54  |  loss_gdl  0.54  |  dice_score  0.46  | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  2500/ 3779 batches |  ms/batch 46747.47 |  loss_dice  0.53  |  loss_gdl  0.53  |  dice_score  0.47  | \n",
      "| epoch   2 |  2600/ 3779 batches |  ms/batch 42133.20 |  loss_dice  0.53  |  loss_gdl  0.53  |  dice_score  0.47  | \n",
      "| epoch   2 |  2700/ 3779 batches |  ms/batch 55628.03 |  loss_dice  0.53  |  loss_gdl  0.53  |  dice_score  0.47  | \n",
      "| epoch   2 |  2800/ 3779 batches |  ms/batch 41728.61 |  loss_dice  0.53  |  loss_gdl  0.53  |  dice_score  0.47  | \n",
      "| epoch   2 |  2900/ 3779 batches |  ms/batch 41858.95 |  loss_dice  0.53  |  loss_gdl  0.53  |  dice_score  0.47  | \n",
      "| epoch   2 |  3000/ 3779 batches |  ms/batch 46878.71 |  loss_dice  0.53  |  loss_gdl  0.53  |  dice_score  0.47  | \n",
      "| epoch   2 |  3100/ 3779 batches |  ms/batch 46789.05 |  loss_dice  0.53  |  loss_gdl  0.53  |  dice_score  0.47  | \n",
      "| epoch   2 |  3200/ 3779 batches |  ms/batch 47745.09 |  loss_dice  0.53  |  loss_gdl  0.53  |  dice_score  0.47  | \n",
      "| epoch   2 |  3300/ 3779 batches |  ms/batch 45802.81 |  loss_dice  0.52  |  loss_gdl  0.52  |  dice_score  0.48  | \n",
      "| epoch   2 |  3400/ 3779 batches |  ms/batch 42903.20 |  loss_dice  0.52  |  loss_gdl  0.52  |  dice_score  0.48  | \n",
      "| epoch   2 |  3500/ 3779 batches |  ms/batch 42945.68 |  loss_dice  0.52  |  loss_gdl  0.52  |  dice_score  0.48  | \n",
      "| epoch   2 |  3600/ 3779 batches |  ms/batch 41138.51 |  loss_dice  0.52  |  loss_gdl  0.52  |  dice_score  0.48  | \n",
      "| epoch   2 |  3700/ 3779 batches |  ms/batch 45581.71 |  loss_dice  0.52  |  loss_gdl  0.52  |  dice_score  0.48  | \n",
      "| epoch   2 |  3779/ 3779 batches |  ms/batch 37854.67 |  loss_dice  0.52  |  loss_gdl  0.52  |  dice_score  0.48  | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   100/  436 batches |  ms/batch 16606.32 |  loss_dice  0.32  |  loss_gdl  0.32  |  dice_score  0.68  | \n",
      "| epoch   2 |   200/  436 batches |  ms/batch 23477.87 |  loss_dice  0.41  |  loss_gdl  0.41  |  dice_score  0.59  | \n",
      "| epoch   2 |   300/  436 batches |  ms/batch 53532.40 |  loss_dice  0.50  |  loss_gdl  0.50  |  dice_score  0.50  | \n",
      "| epoch   2 |   400/  436 batches |  ms/batch 26227.41 |  loss_dice  0.44  |  loss_gdl  0.44  |  dice_score  0.56  | \n",
      "| epoch   2 |   436/  436 batches |  ms/batch 11950.84 |  loss_dice  0.45  |  loss_gdl  0.45  |  dice_score  0.55  | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 1851.29s\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "epochs = 2 # The number of epochs\n",
    "\n",
    "# 儲存權重的路徑\n",
    "path = 'F:/20220309_process4FL/baseline_model/aug/raw/pytorch_test'\n",
    "\n",
    "if os.path.isdir(path)==False:\n",
    "    os.mkdir(path)\n",
    "path = os.path.join(path,\"train\")\n",
    "if os.path.isdir(path)==False:\n",
    "    os.mkdir(path)       \n",
    "filenum = glob.glob(path + \"/exp*\")\n",
    "path = path + \"/exp\" + str(len(filenum)+1)\n",
    "os.mkdir(path)\n",
    "\n",
    "#f = open(path + '/loss_curve.txt', 'a')\n",
    "# 開始訓練\n",
    "traloss = 0\n",
    "valloss = 0\n",
    "rvalloss = 0\n",
    "for epoch in range(1,epochs+1):\n",
    "    if epoch==1:\n",
    "        print('Training start.')\n",
    "    \n",
    "    epoch_start_time = time.time()\n",
    "    tralossnew = train(train_loader,model,loss_fun,optimizer,epoch,path)\n",
    "    print('-' * 89)\n",
    "    vallossnew = validation(val_loader,model,loss_fun,epoch,path)\n",
    "    print('-' * 89)    \n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s'.format(epoch, (time.time() - epoch_start_time)))\n",
    "    print('-' * 89)\n",
    "    \n",
    "    #scheduler.step()\n",
    "    # save best model parameters\n",
    "    f2 = open(path + '/model_info.txt', 'a')\n",
    "    if tralossnew<traloss or epoch ==1: \n",
    "        fname = path + '/best_tra'  + '.tar'\n",
    "        torch.save(model.state_dict(), fname)\n",
    "        traloss = tralossnew\n",
    "        f2.write('| best_tra | epoch {:3d}| '.format(epoch)+'\\r\\n')\n",
    "    if vallossnew<valloss or epoch ==1: \n",
    "        fname = path + '/best_val'  + '.tar'\n",
    "        torch.save(model.state_dict(), fname)\n",
    "        valloss = vallossnew\n",
    "        f2.write('| best_val | epoch {:3d}| '.format(epoch)+'\\r\\n')\n",
    "        \n",
    "\n",
    "fname = path + '/last' + '.tar'\n",
    "torch.save(model.state_dict(), fname)\n",
    "f2.write('Finished!')\n",
    "    \n",
    "#f.close()\n",
    "f2.close()\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f350d067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
