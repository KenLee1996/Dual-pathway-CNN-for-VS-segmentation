{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0657067-e86c-449f-9db3-60de81d837d8",
   "metadata": {},
   "source": [
    "# Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3fc7ab1-1873-445d-ba23-5500740b9637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1.10.2\n"
     ]
    }
   ],
   "source": [
    "# import module\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from itertools import compress\n",
    "\n",
    "import gc\n",
    "\n",
    "# for loss function\n",
    "from typing import Optional\n",
    "from kornia.utils.one_hot import one_hot\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)\n",
    "\n",
    "from models import DP_UNet, DP_resUNet\n",
    "\n",
    "from patch_function import makepatches_overlay, \\\n",
    "makepatches_overlay_normap, \\\n",
    "patchesback_overlay, \\\n",
    "find_ksp_andpadding, \\\n",
    "pad_back, \\\n",
    "pad_for_256, \\\n",
    "pad_back_256,\\\n",
    "patch_inference\n",
    "\n",
    "\n",
    "from data_preprocess_and_loader import Dataset, Dataset_val, Dataset_out\n",
    "\n",
    "from losses_unet3d import DiceLoss, GeneralizedDiceLoss, compute_per_channel_dice\n",
    "\n",
    "from train_and_val import train, validation,\\\n",
    "inference_and_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19bd75d-cea0-4acf-a69d-51f41da26439",
   "metadata": {},
   "source": [
    "# Define Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eb781c8-9d22-4764-8ed8-de23e3f5114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Datasets\n",
    "path_tra_1 = 'E:/BrainTumor_TCVGH/Dataset/Dataset_tcvgh/1_tra'\n",
    "list_tra_1 = os.listdir(path_tra_1)\n",
    "for i in range(len(list_tra_1)):\n",
    "    list_tra_1[i] = path_tra_1+'/'+list_tra_1[i]\n",
    "path_tra_2 = 'F:/Datasets_TPVGH/Dataset_tpvgh/1_tra'\n",
    "list_tra_2 = os.listdir(path_tra_2)\n",
    "for i in range(len(list_tra_2)):\n",
    "    list_tra_2[i] = path_tra_2+'/'+list_tra_2[i]    \n",
    "list_tra = np.append(list_tra_1,list_tra_2)\n",
    "\n",
    "\n",
    "path_val_1 = 'E:/BrainTumor_TCVGH/Dataset/Dataset_tcvgh/2_val'\n",
    "list_val_1 = os.listdir(path_val_1)\n",
    "for i in range(len(list_val_1)):\n",
    "    list_val_1[i] = path_val_1+'/'+list_val_1[i]\n",
    "path_val_2 = 'F:/Datasets_TPVGH/Dataset_tpvgh/2_val'\n",
    "list_val_2 = os.listdir(path_val_2)\n",
    "for i in range(len(list_val_2)):\n",
    "    list_val_2[i] = path_val_2+'/'+list_val_2[i]    \n",
    "list_val = np.append(list_val_1,list_val_2)\n",
    "\n",
    "    \n",
    "path_ts_1 = 'E:/BrainTumor_TCVGH/Dataset/Dataset_tcvgh/3_trial'\n",
    "list_ts_1 = os.listdir(path_ts_1)\n",
    "for i in range(len(list_ts_1)):\n",
    "    list_ts_1[i] = path_ts_1+'/'+list_ts_1[i]\n",
    "path_ts_2 = 'F:/Datasets_TPVGH/Dataset_tpvgh/3_trial'\n",
    "list_ts_2 = os.listdir(path_ts_2)\n",
    "for i in range(len(list_ts_2)):\n",
    "    list_ts_2[i] = path_ts_2+'/'+list_ts_2[i]    \n",
    "list_ts = np.append(list_ts_1,list_ts_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d68ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設置dataloader output\n",
    "train_data = Dataset_out(list_tra)\n",
    "tra_loader = torch.utils.data.DataLoader(\n",
    "    train_data,           \n",
    "    batch_size = 1,                 \n",
    "    shuffle = False)\n",
    "val_data = Dataset_out(list_val)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_data,           \n",
    "    batch_size = 1,                 \n",
    "    shuffle = False)\n",
    "ts_data = Dataset_out(list_ts)\n",
    "ts_loader = torch.utils.data.DataLoader(\n",
    "    ts_data,           \n",
    "    batch_size = 1,                 \n",
    "    shuffle = False)\n",
    "\n",
    "Dataloader = [val_loader, ts_loader]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0413245d-6a7e-4c13-b963-e095aba150dc",
   "metadata": {},
   "source": [
    "# Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec6a8bac-c7f5-4740-9821-296a5e100707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "\n",
    "model = DP_resUNet(img_channels = 2, n_classes = 2).cuda()\n",
    "#model = DP_UNet(img_channels = 2, n_classes = 2).cuda()\n",
    "\n",
    "# define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, gamma=0.95)\n",
    "\n",
    "# loss function\n",
    "criterion_DICE = DiceLoss()\n",
    "criterion_GDL = GeneralizedDiceLoss()\n",
    "\n",
    "loss_fun = (criterion_DICE,criterion_GDL,compute_per_channel_dice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189f1712-15fd-4b7e-a4c4-6eaa2f1eef59",
   "metadata": {},
   "source": [
    "# Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3e3fca5-0fd6-4653-b181-de04a7016b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "PATH = 'F:/Experiments/3D/3DresDP_tc+tp_fin_s24/model_tmp/best_val.tar'\n",
    "own_state = torch.load(PATH)\n",
    "model.load_state_dict(own_state)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4c80e7-e848-47b9-aab5-bf9a708c20e1",
   "metadata": {},
   "source": [
    "# Start to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a5715ea-8d86-4cf1-94d7-06e196b0a9d4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    10/  284 batches | ms/batch 504150.65 | loss_dice  0.10 | loss_gdl  0.19 | \n",
      "|    20/  284 batches | ms/batch 340905.53 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|    30/  284 batches | ms/batch 431443.65 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|    40/  284 batches | ms/batch 1242983.09 | loss_dice  0.15 | loss_gdl  0.30 | \n",
      "|    50/  284 batches | ms/batch 820450.43 | loss_dice  0.15 | loss_gdl  0.28 | \n",
      "|    60/  284 batches | ms/batch 1760086.21 | loss_dice  0.16 | loss_gdl  0.31 | \n",
      "|    70/  284 batches | ms/batch 1311780.41 | loss_dice  0.17 | loss_gdl  0.33 | \n",
      "|    80/  284 batches | ms/batch 1672057.50 | loss_dice  0.17 | loss_gdl  0.33 | \n",
      "|    90/  284 batches | ms/batch 1617142.24 | loss_dice  0.17 | loss_gdl  0.33 | \n",
      "|   100/  284 batches | ms/batch 1801496.47 | loss_dice  0.18 | loss_gdl  0.34 | \n",
      "|   110/  284 batches | ms/batch 583654.80 | loss_dice  0.18 | loss_gdl  0.34 | \n",
      "|   120/  284 batches | ms/batch 92096.88 | loss_dice  0.17 | loss_gdl  0.32 | \n",
      "|   130/  284 batches | ms/batch 93029.63 | loss_dice  0.16 | loss_gdl  0.30 | \n",
      "|   140/  284 batches | ms/batch 96808.29 | loss_dice  0.15 | loss_gdl  0.29 | \n",
      "|   150/  284 batches | ms/batch 91936.40 | loss_dice  0.15 | loss_gdl  0.29 | \n",
      "|   160/  284 batches | ms/batch 92216.83 | loss_dice  0.15 | loss_gdl  0.29 | \n",
      "|   170/  284 batches | ms/batch 104880.38 | loss_dice  0.15 | loss_gdl  0.28 | \n",
      "|   180/  284 batches | ms/batch 107572.29 | loss_dice  0.14 | loss_gdl  0.28 | \n",
      "|   190/  284 batches | ms/batch 96602.25 | loss_dice  0.14 | loss_gdl  0.27 | \n",
      "|   200/  284 batches | ms/batch 119248.66 | loss_dice  0.14 | loss_gdl  0.27 | \n",
      "|   210/  284 batches | ms/batch 98253.95 | loss_dice  0.14 | loss_gdl  0.27 | \n",
      "|   220/  284 batches | ms/batch 123523.37 | loss_dice  0.14 | loss_gdl  0.26 | \n",
      "|   230/  284 batches | ms/batch 161411.30 | loss_dice  0.14 | loss_gdl  0.27 | \n",
      "|   240/  284 batches | ms/batch 156498.88 | loss_dice  0.14 | loss_gdl  0.26 | \n",
      "|   250/  284 batches | ms/batch 294374.55 | loss_dice  0.13 | loss_gdl  0.26 | \n",
      "|   260/  284 batches | ms/batch 350533.30 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   270/  284 batches | ms/batch 350654.45 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   280/  284 batches | ms/batch 345699.87 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   284/  284 batches | ms/batch 136457.44 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|    10/  428 batches | ms/batch 489828.67 | loss_dice  0.16 | loss_gdl  0.32 | \n",
      "|    20/  428 batches | ms/batch 494859.56 | loss_dice  0.14 | loss_gdl  0.28 | \n",
      "|    30/  428 batches | ms/batch 972937.81 | loss_dice  0.17 | loss_gdl  0.33 | \n",
      "|    40/  428 batches | ms/batch 659779.07 | loss_dice  0.18 | loss_gdl  0.36 | \n",
      "|    50/  428 batches | ms/batch 494973.25 | loss_dice  0.16 | loss_gdl  0.32 | \n",
      "|    60/  428 batches | ms/batch 1254085.67 | loss_dice  0.17 | loss_gdl  0.33 | \n",
      "|    70/  428 batches | ms/batch 1893219.47 | loss_dice  0.16 | loss_gdl  0.32 | \n",
      "|    80/  428 batches | ms/batch 1889306.57 | loss_dice  0.18 | loss_gdl  0.34 | \n",
      "|    90/  428 batches | ms/batch 1882208.53 | loss_dice  0.18 | loss_gdl  0.34 | \n",
      "|   100/  428 batches | ms/batch 1845897.43 | loss_dice  0.18 | loss_gdl  0.34 | \n",
      "|   110/  428 batches | ms/batch 1049512.22 | loss_dice  0.18 | loss_gdl  0.34 | \n",
      "|   120/  428 batches | ms/batch 91803.51 | loss_dice  0.17 | loss_gdl  0.32 | \n",
      "|   130/  428 batches | ms/batch 89805.66 | loss_dice  0.16 | loss_gdl  0.31 | \n",
      "|   140/  428 batches | ms/batch 94865.10 | loss_dice  0.15 | loss_gdl  0.29 | \n",
      "|   150/  428 batches | ms/batch 93514.35 | loss_dice  0.15 | loss_gdl  0.28 | \n",
      "|   160/  428 batches | ms/batch 91775.22 | loss_dice  0.14 | loss_gdl  0.27 | \n",
      "|   170/  428 batches | ms/batch 106329.95 | loss_dice  0.14 | loss_gdl  0.27 | \n",
      "|   180/  428 batches | ms/batch 94241.52 | loss_dice  0.14 | loss_gdl  0.26 | \n",
      "|   190/  428 batches | ms/batch 96162.97 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   200/  428 batches | ms/batch 90810.14 | loss_dice  0.13 | loss_gdl  0.24 | \n",
      "|   210/  428 batches | ms/batch 143502.77 | loss_dice  0.13 | loss_gdl  0.24 | \n",
      "|   220/  428 batches | ms/batch 113713.69 | loss_dice  0.13 | loss_gdl  0.24 | \n",
      "|   230/  428 batches | ms/batch 116419.76 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   240/  428 batches | ms/batch 114337.17 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   250/  428 batches | ms/batch 93385.17 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   260/  428 batches | ms/batch 91822.44 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   270/  428 batches | ms/batch 98948.39 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   280/  428 batches | ms/batch 117776.88 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   290/  428 batches | ms/batch 128986.86 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   300/  428 batches | ms/batch 110355.29 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   310/  428 batches | ms/batch 109605.76 | loss_dice  0.13 | loss_gdl  0.24 | \n",
      "|   320/  428 batches | ms/batch 123718.75 | loss_dice  0.13 | loss_gdl  0.24 | \n",
      "|   330/  428 batches | ms/batch 275247.22 | loss_dice  0.13 | loss_gdl  0.24 | \n",
      "|   340/  428 batches | ms/batch 304967.05 | loss_dice  0.13 | loss_gdl  0.24 | \n",
      "|   350/  428 batches | ms/batch 317408.50 | loss_dice  0.13 | loss_gdl  0.24 | \n",
      "|   360/  428 batches | ms/batch 302110.02 | loss_dice  0.13 | loss_gdl  0.24 | \n",
      "|   370/  428 batches | ms/batch 297982.77 | loss_dice  0.13 | loss_gdl  0.24 | \n",
      "|   380/  428 batches | ms/batch 301620.72 | loss_dice  0.13 | loss_gdl  0.24 | \n",
      "|   390/  428 batches | ms/batch 321140.26 | loss_dice  0.13 | loss_gdl  0.24 | \n",
      "|   400/  428 batches | ms/batch 300909.13 | loss_dice  0.13 | loss_gdl  0.24 | \n",
      "|   410/  428 batches | ms/batch 317269.19 | loss_dice  0.13 | loss_gdl  0.24 | \n",
      "|   420/  428 batches | ms/batch 294816.66 | loss_dice  0.12 | loss_gdl  0.24 | \n",
      "|   428/  428 batches | ms/batch 234921.71 | loss_dice  0.12 | loss_gdl  0.24 | \n"
     ]
    }
   ],
   "source": [
    "sav_path = 'F:/Experiments/3D/3DresDP_tc+tp_fin_s24/results_bestval_64645'\n",
    "str_ = ['2_val','3_trial']\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    path = sav_path + '/' + str_[i]    \n",
    "    f = open(sav_path + '/loss_curve.txt', 'a')\n",
    "    inference_and_output(save_mode=True,\n",
    "                        data_loader = Dataloader[i],\n",
    "                        model = model,\n",
    "                        loss_fun = loss_fun,\n",
    "                        f = f,\n",
    "                        kernel_size = (256,256,24),\n",
    "                        stride = (64,64,5),\n",
    "                        inf_pnum = 10,\n",
    "                        sav_path = path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6350dbeb-2c27-449b-87f4-b2d1c54e8e82",
   "metadata": {},
   "source": [
    "# TMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d516e6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    10/  284 batches | ms/batch 278816.11 | loss_dice  0.11 | loss_gdl  0.21 | \n",
      "|    20/  284 batches | ms/batch 202341.91 | loss_dice  0.14 | loss_gdl  0.27 | \n",
      "|    30/  284 batches | ms/batch 254592.80 | loss_dice  0.13 | loss_gdl  0.26 | \n",
      "|    40/  284 batches | ms/batch 541778.95 | loss_dice  0.16 | loss_gdl  0.30 | \n",
      "|    50/  284 batches | ms/batch 396862.11 | loss_dice  0.15 | loss_gdl  0.29 | \n",
      "|    60/  284 batches | ms/batch 768272.19 | loss_dice  0.16 | loss_gdl  0.31 | \n",
      "|    70/  284 batches | ms/batch 588260.55 | loss_dice  0.17 | loss_gdl  0.33 | \n",
      "|    80/  284 batches | ms/batch 730492.87 | loss_dice  0.18 | loss_gdl  0.34 | \n",
      "|    90/  284 batches | ms/batch 689943.77 | loss_dice  0.17 | loss_gdl  0.33 | \n",
      "|   100/  284 batches | ms/batch 766464.69 | loss_dice  0.18 | loss_gdl  0.34 | \n",
      "|   110/  284 batches | ms/batch 283901.87 | loss_dice  0.18 | loss_gdl  0.34 | \n",
      "|   120/  284 batches | ms/batch 80393.02 | loss_dice  0.17 | loss_gdl  0.32 | \n",
      "|   130/  284 batches | ms/batch 80872.03 | loss_dice  0.16 | loss_gdl  0.31 | \n",
      "|   140/  284 batches | ms/batch 83087.31 | loss_dice  0.16 | loss_gdl  0.30 | \n",
      "|   150/  284 batches | ms/batch 78730.10 | loss_dice  0.15 | loss_gdl  0.29 | \n",
      "|   160/  284 batches | ms/batch 76913.21 | loss_dice  0.15 | loss_gdl  0.29 | \n",
      "|   170/  284 batches | ms/batch 85956.71 | loss_dice  0.15 | loss_gdl  0.29 | \n",
      "|   180/  284 batches | ms/batch 91167.83 | loss_dice  0.15 | loss_gdl  0.28 | \n",
      "|   190/  284 batches | ms/batch 83105.26 | loss_dice  0.14 | loss_gdl  0.27 | \n",
      "|   200/  284 batches | ms/batch 98042.58 | loss_dice  0.14 | loss_gdl  0.27 | \n",
      "|   210/  284 batches | ms/batch 84234.14 | loss_dice  0.14 | loss_gdl  0.27 | \n",
      "|   220/  284 batches | ms/batch 100810.03 | loss_dice  0.14 | loss_gdl  0.27 | \n",
      "|   230/  284 batches | ms/batch 123328.33 | loss_dice  0.14 | loss_gdl  0.27 | \n",
      "|   240/  284 batches | ms/batch 120860.86 | loss_dice  0.14 | loss_gdl  0.26 | \n",
      "|   250/  284 batches | ms/batch 185489.96 | loss_dice  0.14 | loss_gdl  0.26 | \n",
      "|   260/  284 batches | ms/batch 214724.80 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   270/  284 batches | ms/batch 216416.57 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   280/  284 batches | ms/batch 211418.56 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   284/  284 batches | ms/batch 89755.97 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|    10/  428 batches | ms/batch 280022.47 | loss_dice  0.17 | loss_gdl  0.34 | \n",
      "|    20/  428 batches | ms/batch 280907.40 | loss_dice  0.15 | loss_gdl  0.30 | \n",
      "|    30/  428 batches | ms/batch 457849.49 | loss_dice  0.17 | loss_gdl  0.34 | \n",
      "|    40/  428 batches | ms/batch 332586.18 | loss_dice  0.19 | loss_gdl  0.37 | \n",
      "|    50/  428 batches | ms/batch 262092.53 | loss_dice  0.17 | loss_gdl  0.34 | \n",
      "|    60/  428 batches | ms/batch 568602.41 | loss_dice  0.18 | loss_gdl  0.34 | \n",
      "|    70/  428 batches | ms/batch 821367.79 | loss_dice  0.17 | loss_gdl  0.33 | \n",
      "|    80/  428 batches | ms/batch 810995.64 | loss_dice  0.19 | loss_gdl  0.36 | \n",
      "|    90/  428 batches | ms/batch 814667.31 | loss_dice  0.18 | loss_gdl  0.35 | \n",
      "|   100/  428 batches | ms/batch 803348.38 | loss_dice  0.19 | loss_gdl  0.35 | \n",
      "|   110/  428 batches | ms/batch 458737.26 | loss_dice  0.18 | loss_gdl  0.35 | \n",
      "|   120/  428 batches | ms/batch 80807.13 | loss_dice  0.17 | loss_gdl  0.33 | \n",
      "|   130/  428 batches | ms/batch 79504.37 | loss_dice  0.17 | loss_gdl  0.32 | \n",
      "|   140/  428 batches | ms/batch 83774.41 | loss_dice  0.16 | loss_gdl  0.30 | \n",
      "|   150/  428 batches | ms/batch 81195.59 | loss_dice  0.15 | loss_gdl  0.29 | \n",
      "|   160/  428 batches | ms/batch 80174.71 | loss_dice  0.15 | loss_gdl  0.28 | \n",
      "|   170/  428 batches | ms/batch 91156.11 | loss_dice  0.14 | loss_gdl  0.27 | \n",
      "|   180/  428 batches | ms/batch 82875.35 | loss_dice  0.14 | loss_gdl  0.26 | \n",
      "|   190/  428 batches | ms/batch 84109.16 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   200/  428 batches | ms/batch 80327.50 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   210/  428 batches | ms/batch 122059.44 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   220/  428 batches | ms/batch 103797.95 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   230/  428 batches | ms/batch 104595.11 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   240/  428 batches | ms/batch 104326.46 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   250/  428 batches | ms/batch 90121.91 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   260/  428 batches | ms/batch 91088.81 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   270/  428 batches | ms/batch 95616.30 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   280/  428 batches | ms/batch 107956.94 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   290/  428 batches | ms/batch 110628.98 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   300/  428 batches | ms/batch 100290.42 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   310/  428 batches | ms/batch 100254.17 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   320/  428 batches | ms/batch 111647.80 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   330/  428 batches | ms/batch 196743.22 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   340/  428 batches | ms/batch 214027.48 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   350/  428 batches | ms/batch 224665.27 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   360/  428 batches | ms/batch 220259.01 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   370/  428 batches | ms/batch 208078.33 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   380/  428 batches | ms/batch 217269.34 | loss_dice  0.13 | loss_gdl  0.24 | \n",
      "|   390/  428 batches | ms/batch 228542.40 | loss_dice  0.13 | loss_gdl  0.25 | \n",
      "|   400/  428 batches | ms/batch 213771.82 | loss_dice  0.13 | loss_gdl  0.24 | \n",
      "|   410/  428 batches | ms/batch 228940.14 | loss_dice  0.13 | loss_gdl  0.24 | \n",
      "|   420/  428 batches | ms/batch 210843.79 | loss_dice  0.13 | loss_gdl  0.24 | \n",
      "|   428/  428 batches | ms/batch 169755.91 | loss_dice  0.13 | loss_gdl  0.24 | \n"
     ]
    }
   ],
   "source": [
    "sav_path = 'F:/Experiments/3D/3DresDP_tc+tp_fin_s24/results_bestval_646412'\n",
    "str_ = ['2_val','3_trial']\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    path = sav_path + '/' + str_[i]    \n",
    "    f = open(sav_path + '/loss_curve.txt', 'a')\n",
    "    inference_and_output(save_mode=True,\n",
    "                        data_loader = Dataloader[i],\n",
    "                        model = model,\n",
    "                        loss_fun = loss_fun,\n",
    "                        f = f,\n",
    "                        kernel_size = (256,256,24),\n",
    "                        stride = (64,64,12),\n",
    "                        inf_pnum = 10,\n",
    "                        sav_path = path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a0578d-3165-459a-9a47-142f68df4643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
