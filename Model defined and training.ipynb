{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================Data Generator==========================================================\n",
    "import os\n",
    "import numpy as np\n",
    "from  scipy import ndimage\n",
    "import nibabel as nib\n",
    "epoch_num = 40\n",
    "kepoch_num = 20\n",
    "batch_size = 4\n",
    "tbatch_size = 4\n",
    "spath = 'save_path'\n",
    "os.mkdir(spath)\n",
    "train_image_path = 'data_path'\n",
    "test_image_path = 'test_data_path'\n",
    "\n",
    "label = []\n",
    "path = []\n",
    "tlabel = []\n",
    "tpath = []\n",
    "\n",
    "k = os.listdir(train_image_path)\n",
    "for j in k:\n",
    "    path.append(train_image_path + '/' + j)   \n",
    "    label.append(train_image_path + '/' + j)\n",
    "k = os.listdir(test_image_path)\n",
    "for j in k:\n",
    "    path.append(test_image_path + '/' + j)   \n",
    "    label.append(test_image_path + '/' + j)\n",
    "    \n",
    "steps_per_epoch = int(len(path)/batch_size)\n",
    "tsteps_per_epoch = int(len(tpath)/tbatch_size)\n",
    "\n",
    "def process(data_dir, label):\n",
    "    if '_' in data_dir:\n",
    "        img = nib.load(data_dir + '/T1W+C.nii').get_fdata()\n",
    "        img2 = nib.load(data_dir + '/T2W.nii').get_fdata()\n",
    "    else:\n",
    "        img = nib.load(data_dir + '/T1W+C.nii').get_fdata()\n",
    "        img2 = nib.load(data_dir + '/T2W.nii').get_fdata()\n",
    "    lb = nib.load(label + '/TV_MASK.nii').get_fdata()\n",
    "    \n",
    "    img[np.where(np.isnan(img))] = 0\n",
    "    img2[np.where(np.isnan(img2))] = 0\n",
    "    lb[np.where(np.isnan(lb))] = 0    \n",
    "    \n",
    "    #=======augmentation=========#\n",
    "    \n",
    "    #flip_ratio = np.random.rand(1)\n",
    "    #if flip_ratio >= 0.5:\n",
    "        #img = np.fliplr(img)\n",
    "        #img2 = np.fliplr(img2)\n",
    "        #lb = np.fliplr(lb)\n",
    "    #rot_angle = np.random.randint(-30, 30)\n",
    "    #img = ndimage.rotate(img, rot_angle, reshape=False)\n",
    "    #img2 = ndimage.rotate(img2, rot_angle, reshape=False)\n",
    "    #lb = ndimage.rotate(lb, rot_angle, reshape=False)\n",
    "    \n",
    "    #=======augmentation=========#\n",
    "    \n",
    "    img = (img-np.mean(img))/(np.std(img))\n",
    "    img2 = (img2-np.mean(img2))/(np.std(img2))\n",
    "    \n",
    "    img = np.expand_dims(img,-1)\n",
    "    img2 = np.expand_dims(img2,-1)\n",
    "    lb = np.expand_dims(lb,-1)  \n",
    "    imgn = np.concatenate((img,img2),-1)\n",
    "    return np.array(imgn,dtype=np.float32), np.array(lb,dtype=np.float32)\n",
    "def tprocess(data_dir, label):\n",
    "    if '_' in data_dir:\n",
    "        img = nib.load(data_dir + '/T1W+C.nii').get_fdata()\n",
    "        img2 = nib.load(data_dir + '/T2W.nii').get_fdata()\n",
    "    else:\n",
    "        img = nib.load(data_dir + '/T1W+C.nii').get_fdata()\n",
    "        img2 = nib.load(data_dir + '/T2W.nii').get_fdata()\n",
    "    lb = nib.load(label + '/TV_MASK.nii').get_fdata()\n",
    "    \n",
    "    img[np.where(np.isnan(img))] = 0\n",
    "    img2[np.where(np.isnan(img2))] = 0\n",
    "    lb[np.where(np.isnan(lb))] = 0    \n",
    "    \n",
    "    img = (img-np.mean(img))/(np.std(img))\n",
    "    img2 = (img2-np.mean(img2))/(np.std(img2))\n",
    "    \n",
    "    img = np.expand_dims(img,-1)\n",
    "    img2 = np.expand_dims(img2,-1)\n",
    "    lb = np.expand_dims(lb,-1)  \n",
    "    imgn = np.concatenate((img,img2),-1)\n",
    "    return np.array(imgn,dtype=np.float32), np.array(lb,dtype=np.float32)\n",
    "\n",
    "def data_generator(path,label, batch_size, step):\n",
    "    import numpy as np\n",
    "    import os\n",
    "    trpath = []\n",
    "    trlabel = []\n",
    "    trpath = path.copy()\n",
    "    trlabel = label.copy()\n",
    "    i = 0\n",
    "    while i <= step:\n",
    "        if i == step:            \n",
    "            i = 0            \n",
    "        if i == 0:            \n",
    "            rbatch_path = []\n",
    "            rbatch_label = []            \n",
    "            index = np.random.permutation(len(trpath))\n",
    "            rrbatch_path = []\n",
    "            rrbatch_label = []\n",
    "            index = np.random.permutation(len(trpath))\n",
    "            for ind in index:\n",
    "                rrbatch_path.append(trpath[ind])\n",
    "                rrbatch_label.append(trlabel[ind])\n",
    "        batch_img = []\n",
    "        batch_gt = []    \n",
    "        for fi in range(batch_size):\n",
    "            if (batch_size*i+fi) == len(rrbatch_path):\n",
    "                break\n",
    "            else:\n",
    "                img, gt = process(rrbatch_path[batch_size*i+fi],rrbatch_label[batch_size*i+fi])\n",
    "                batch_img.append(img)\n",
    "                batch_gt.append(gt)\n",
    "        i += 1\n",
    "        yield np.array(batch_img), np.array(batch_gt)\n",
    "        \n",
    "def tdata_generator(tpath, tlabel, tbatch_size, step):\n",
    "    import numpy as np\n",
    "    import os    \n",
    "    i = 0\n",
    "    while i <= step:\n",
    "        if i == step:\n",
    "            i = 0                    \n",
    "        batch_img = []\n",
    "        batch_gt = []\n",
    "        if tbatch_size == 1:\n",
    "            img, gt = tprocess(tpath[tbatch_size*i],tlabel[tbatch_size*i])\n",
    "            batch_img.append(img)\n",
    "            batch_gt.append(gt)\n",
    "        else:\n",
    "            for fi in range(tbatch_size):\n",
    "                img, gt = tprocess(tpath[tbatch_size*i+fi],tlabel[tbatch_size*i+fi])            \n",
    "                batch_img.append(img)\n",
    "                batch_gt.append(gt)\n",
    "        i += 1\n",
    "        yield np.array(batch_img), np.array(batch_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================================================Model==============================================================================\n",
    "from keras.optimizers import *\n",
    "from keras.models import *\n",
    "from keras import regularizers\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from switchnorm import SwitchNormalization\n",
    "from keras.layers import *\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    smooth = 1e-5\n",
    "    intersection = K.sum(y_true * y_pred,axis=[1,2,3,4])\n",
    "    return K.mean((2. * intersection + smooth) / (K.sum(y_true,axis=[1,2,3,4]) + K.sum(y_pred,axis=[1,2,3,4]) + smooth),axis=0)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "def tversky(y_true, y_pred):\n",
    "    y_true_pos = K.flatten(y_true)\n",
    "    y_pred_pos = K.flatten(y_pred)\n",
    "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n",
    "    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n",
    "    alpha = 0.3\n",
    "    smooth = 1e-5\n",
    "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
    "\n",
    "def tversky_loss(y_true, y_pred):\n",
    "    return 1 - tversky(y_true,y_pred)\n",
    "#https://blog.csdn.net/thunder_k/article/details/99202013\n",
    "\n",
    "d = []\n",
    "l = []\n",
    "vd = []\n",
    "vl = []\n",
    "para_num = 2 #T1W+C and T2W images\n",
    "inputs = Input((256,216,20,para_num))\n",
    "conv01 = Conv3D(10,kernel_size=(3,3,1),strides=(1,1,1),padding='same',activation='relu')(inputs)\n",
    "conv01 = SwitchNormalization()(conv01)\n",
    "conv02 = Conv3D(10,kernel_size=(1,1,3),strides=(1,1,1),padding='same',activation='relu')(inputs)\n",
    "conv02 = SwitchNormalization()(conv02)\n",
    "\n",
    "conv11 = Conv3D(16,kernel_size=(3,3,1),strides=(1,1,1),padding='same',activation='relu')(conv01)\n",
    "conv11 = SwitchNormalization()(conv11)\n",
    "conv12 = Conv3D(16,kernel_size=(1,1,3),strides=(1,1,1),padding='same',activation='relu')(conv02)\n",
    "conv12 = SwitchNormalization()(conv12)\n",
    "\n",
    "conv21 = MaxPooling3D(pool_size=(2,2,1),strides=(2,2,1),padding='same')(conv11)\n",
    "conv21 = Conv3D(32,kernel_size=(3,3,1),strides=(1,1,1),padding='same',activation='relu')(conv21)\n",
    "conv21 = SwitchNormalization()(conv21)\n",
    "conv22 = MaxPooling3D(pool_size=(2,2,1),strides=(2,2,1),padding='same')(conv12)\n",
    "conv22 = Conv3D(32,kernel_size=(1,1,3),strides=(1,1,1),padding='same',activation='relu')(conv22)\n",
    "conv22 = SwitchNormalization()(conv22)\n",
    "\n",
    "conv31 = Conv3D(32,kernel_size=(3,3,1),strides=(1,1,1),padding='same',activation='relu')(conv21)\n",
    "conv31 = SwitchNormalization()(conv31)\n",
    "conv32 = Conv3D(32,kernel_size=(1,1,3),strides=(1,1,1),padding='same',activation='relu')(conv22)\n",
    "conv32 = SwitchNormalization()(conv32)\n",
    "\n",
    "convc = concatenate([MaxPooling3D(pool_size=(2,2,1),strides=(2,2,1),padding='same')(conv31),MaxPooling3D(pool_size=(2,2,1),strides=(2,2,1),padding='same')(conv32)],axis=-1)\n",
    "convc = Conv3D(64,kernel_size=(3,3,3),strides=(1,1,1),padding='same',activation='relu')(convc)\n",
    "convc = SwitchNormalization()(convc)\n",
    "\n",
    "convc1 = Conv3D(32,kernel_size=(3,3,3),strides=(1,1,1),padding='same',activation='relu')(convc)\n",
    "convc1 = SwitchNormalization()(convc1)\n",
    "\n",
    "conv4 = Conv3DTranspose(16,kernel_size=(3,3,3),strides=(2,2,1),padding='same',activation='relu')(convc1)\n",
    "conv4 = SwitchNormalization()(conv4)\n",
    "conv4 = concatenate([Conv3D(32, kernel_size=(1,1,1),strides=(1,1,1),padding='same')(concatenate([conv31,conv32],axis=-1)),conv4],axis=-1)\n",
    "\n",
    "conv5 = Conv3D(24,kernel_size=(3,3,3),strides=(1,1,1),padding='same',activation='relu')(conv4)\n",
    "conv5 = SwitchNormalization()(conv5)\n",
    "\n",
    "conv6 = Conv3DTranspose(12,kernel_size=(3,3,3),strides=(2,2,1),padding='same',activation='relu')(conv5)\n",
    "conv6 = SwitchNormalization()(conv6)\n",
    "conv6 = concatenate([Conv3D(16, kernel_size=(1,1,1),strides=(1,1,1),padding='same')(concatenate([conv11,conv12],axis=-1)),conv6],axis=-1)\n",
    "\n",
    "conv7 = Conv3D(14,kernel_size=(3,3,3),strides=(1,1,1),padding='same',activation='relu')(conv6)\n",
    "conv7 = SwitchNormalization()(conv7)\n",
    "\n",
    "conv18 = Conv3D(1,kernel_size=(1,1,1),strides=(1,1,1),padding='same',activation='sigmoid')(conv7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================Training configuration===============================================================\n",
    "model = Model(inputs, conv18)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)\n",
    "\n",
    "#====if have 2+ GPUS====\n",
    "#parallel_model = multi_gpu_model(model, gpus=2)\n",
    "# replace the 'model' below to 'parallel_model'\n",
    "#=======================\n",
    "\n",
    "model.compile(optimizer = Adam(lr=1e-3), loss = dice_coef_loss, metrics = [dice_coef])\n",
    "modelcheckpoint = ModelCheckpoint(spath + 'model.h5',\n",
    "                                     monitor='dice_coef',save_best_only=True,mode='max')\n",
    "history = model.fit_generator(\n",
    "    data_generator(path, label, batch_size, steps_per_epoch),\n",
    "    epochs=epoch_num,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=tdata_generator(tpath, tlabel, tbatch_size, steps_of_test),\n",
    "    validation_steps = steps_of_test,\n",
    "    callbacks=[modelcheckpoint])\n",
    "\n",
    "d = history.history['dice_coef']\n",
    "vd = history.history['val_dice_coef']\n",
    "l = history.history['loss']\n",
    "vl = history.history['val_loss']\n",
    "\n",
    "model = Model(inputs, conv18)\n",
    "model.compile(optimizer=SGD(lr=1e-4,momentum=0.9),loss = dice_coef_loss, metrics = [dice_coef])\n",
    "model.load_weights(spath + 'model.h5')\n",
    "modelcheckpoint = ModelCheckpoint((spath + 'k'+ str(kepoch_num) + 'model.h5'),\n",
    "                                  monitor='dice_coef',save_best_only=True,mode='max')\n",
    "mhistory = model.fit_generator(\n",
    "    data_generator(path, label, batch_size, steps_per_epoch),\n",
    "    epochs=kepoch_num,    \n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=tdata_generator(tpath, tlabel, tbatch_size, steps_of_test),\n",
    "    validation_steps = steps_of_test,\n",
    "    callbacks=[modelcheckpoint])\n",
    "\n",
    "d[len(d):len(d)] = mhistory.history['dice_coef']\n",
    "vd[len(vd):len(vd)] = mhistory.history['val_dice_coef']\n",
    "l[len(l):len(l)] = mhistory.history['loss']\n",
    "vl[len(vl):len(vl)] = mhistory.history['val_loss']\n",
    "\n",
    "import pandas as pd    \n",
    "df = pd.DataFrame({'trdice':d,\n",
    "                       'trloss':l,\n",
    "                       'vdice':vd,\n",
    "                       'vloss':vl,\n",
    "                  })\n",
    "writer = pd.ExcelWriter(spath + '/Dice&loss.xlsx')\n",
    "df.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n",
    "\n",
    "#====if parallel_model was used====\n",
    "#p_model = load_model(spath + 'keras_M4.model',custom_objects={'tversky_loss': tversky_loss,'dice_coef':dice_coef})\n",
    "#o_model = p_model.layers[-2]\n",
    "#o_model.save(spath + 'k'+ str(kepoch_num) + 'keras_M4_single.model')\n",
    "#==================================\n",
    "\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
